#!/usr/bin/env python3
"""Single-file utility for running .prompt scripts."""
import sys
import os
import json
import re
import hashlib
import urllib.request
import urllib.error
import importlib.util
import inspect
import argparse

# Global config state (loaded once at startup)
CONFIG = {
    "files": {},      # Merged config from all config files
    "env": {},        # Parsed from RUNPROMPT_* env vars
    "args": {},       # From command line arguments
}

# Config keys that support the cascade
CONFIG_KEYS = {
    "model", "default_model", "tool_path", "base_url", "cache", "cache_dir",
    "safe_yes", "verbose", "anthropic_api_key", "openai_api_key",
    "google_api_key", "openrouter_api_key",
}

PROVIDERS = {
    "openrouter": {
        "url": "https://openrouter.ai/api/v1/chat/completions",
        "env": "OPENROUTER_API_KEY",
    },
    "googleai": {
        "url": "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions",
        "env": "GOOGLE_API_KEY",
    },
    "anthropic": {
        "url": "https://api.anthropic.com/v1/messages",
        "env": "ANTHROPIC_API_KEY",
    },
    "openai": {
        "url": "https://api.openai.com/v1/chat/completions",
        "env": "OPENAI_API_KEY",
    },
}

RED = "\033[31m"
YELLOW = "\033[33m"
RESET = "\033[0m"
TIMEOUT = 120

# === CONFIGURATION CASCADE ===


def load_config_files():
    """Load config from cascade of config file locations (lowest to highest priority)."""
    config = {}
    locations = [
        os.path.join(os.path.expanduser("~"), ".runprompt", "config.yml"),
        os.path.join(
            os.environ.get("XDG_CONFIG_HOME", os.path.expanduser("~/.config")),
            "runprompt", "config.yml"
        ),
        os.path.join(".", ".runprompt", "config.yml"),
    ]
    for path in locations:
        if os.path.exists(path):
            try:
                with open(path, "r") as f:
                    file_config = parse_yaml(f.read())
                    if file_config:
                        for key, value in file_config.items():
                            config[normalize_key(key)] = value
            except Exception as e:
                print("%sWarning: Could not load config from %s: %s%s" %
                      (YELLOW, path, e, RESET), file=sys.stderr)
    return config


def load_config_env():
    """Load config from RUNPROMPT_* environment variables."""
    config = {}
    for env_key, env_value in os.environ.items():
        if env_key.startswith("RUNPROMPT_"):
            key = normalize_key(env_key[10:])
            if key in ("cache_dir",):
                config[key] = env_value
            else:
                config[key] = parse_yaml_value(env_value)
    return config


def normalize_key(key):
    """Normalize config key: lowercase, underscores instead of hyphens."""
    return key.lower().replace("-", "_")


def get_conf(key, default=None):
    """Get config value with cascade priority: files < env < args."""
    key = normalize_key(key)
    # Check args first (highest priority)
    if key in CONFIG["args"]:
        return CONFIG["args"][key]
    # Check env vars
    if key in CONFIG["env"]:
        return CONFIG["env"][key]
    # Check config files
    if key in CONFIG["files"]:
        return CONFIG["files"][key]
    return default


def get_api_key(provider):
    """Get API key for provider, checking config cascade then native env var."""
    key_name = provider + "_api_key"
    # First check config cascade
    from_conf = get_conf(key_name)
    if from_conf:
        return from_conf
    # Fall back to native env var (e.g. ANTHROPIC_API_KEY)
    env_var = PROVIDERS.get(provider, {}).get("env")
    if env_var:
        return os.environ.get(env_var)
    return None


def init_config(args):
    """Initialize global config from all sources."""
    CONFIG["files"] = load_config_files()
    CONFIG["env"] = load_config_env()
    # Convert args to dict
    args_dict = {}
    if args.verbose:
        args_dict["verbose"] = True
    if args.cache:
        args_dict["cache"] = True
    if args.safe_yes:
        args_dict["safe_yes"] = True
    if args.base_url:
        args_dict["base_url"] = args.base_url
    if args.tool_path:
        args_dict["tool_path"] = args.tool_path
    # Include overrides from --key=value
    for key, value in args.overrides.items():
        args_dict[normalize_key(key)] = value
    CONFIG["args"] = args_dict


# === MAIN ENTRY POINT ===


def main():
    args = parse_args(sys.argv[1:])
    init_config(args)

    if args.clear_cache:
        clear_cache()
        sys.exit(0)

    use_cache = get_conf("cache", False)

    if len(args.remaining) < 1:
        print("Usage: runprompt [options] <prompt_file>", file=sys.stderr)
        print("Try 'runprompt --help' for more information.", file=sys.stderr)
        sys.exit(1)
    prompt_path = args.remaining[0]
    meta, template = parse_prompt_file(prompt_path)
    meta = apply_overrides(meta)
    # Apply model from config cascade if not in frontmatter
    if not meta.get("model"):
        if get_conf("model"):
            meta["model"] = get_conf("model")
        elif get_conf("default_model"):
            meta["model"] = get_conf("default_model")
    for key, value in args.overrides.items():
        log("Override from arg --%s: %s" % (key, value))
        if key == "tools" and isinstance(value, str):
            # Parse comma-separated tools
            meta[key] = [t.strip() for t in value.split(",")]
        else:
            meta[key] = value
    model_str = meta.get("model", "")
    if not model_str:
        print("No model specified in prompt file", file=sys.stderr)
        sys.exit(1)
    provider, model = parse_model_string(model_str)
    if not provider:
        print("No provider in model string", file=sys.stderr)
        sys.exit(1)
    # Collect extra args after prompt file
    extra_args = args.remaining[1:] if len(args.remaining) > 1 else []
    args_str = " ".join(extra_args)
    log("Extra args: %s" % args_str)

    raw_stdin = read_stdin()
    variables = {"STDIN": raw_stdin or "", "ARGS": args_str}
    # Determine INPUT: prefer STDIN if provided, otherwise use ARGS
    if raw_stdin:
        variables["INPUT"] = raw_stdin
    else:
        variables["INPUT"] = args_str
    # Parse STDIN as JSON if provided
    if raw_stdin:
        try:
            parsed = json.loads(raw_stdin)
            variables.update(parsed)
            log("Parsed STDIN as JSON")
        except ValueError:
            log("STDIN is not JSON, treating as raw string")
            input_schema = meta.get("input", {}).get("schema", {})
            if input_schema:
                first_key = list(input_schema.keys())[0]
                variables[first_key] = raw_stdin
            else:
                variables["input"] = raw_stdin
    # Parse ARGS as JSON if provided (and no STDIN to avoid conflicts)
    elif args_str:
        try:
            parsed = json.loads(args_str)
            variables.update(parsed)
            log("Parsed ARGS as JSON")
        except ValueError:
            log("ARGS is not JSON, treating as raw string")
            input_schema = meta.get("input", {}).get("schema", {})
            if input_schema:
                first_key = list(input_schema.keys())[0]
                variables[first_key] = args_str
    prompt = render_template(template, variables)
    log("Rendered prompt: %s" % prompt)
    output_config = meta.get("output", {})

    # Build tool search paths
    search_paths = []
    search_paths.append(os.getcwd())
    prompt_dir = os.path.dirname(os.path.abspath(prompt_path))
    if prompt_dir not in search_paths:
        search_paths.append(prompt_dir)
    # Add tool paths from config cascade
    conf_tool_paths = get_conf("tool_path", [])
    if isinstance(conf_tool_paths, str):
        conf_tool_paths = [conf_tool_paths]
    for tp in conf_tool_paths:
        abs_tp = os.path.abspath(tp)
        if abs_tp not in search_paths:
            search_paths.append(abs_tp)
    # Add default tool paths from config directories
    default_tool_dirs = [
        os.path.join(".", ".runprompt", "tools"),
        os.path.join(
            os.environ.get("XDG_CONFIG_HOME", os.path.expanduser("~/.config")),
            "runprompt", "tools"
        ),
        os.path.join(os.path.expanduser("~"), ".runprompt", "tools"),
    ]
    for td in default_tool_dirs:
        abs_td = os.path.abspath(td)
        if abs_td not in search_paths and os.path.isdir(abs_td):
            search_paths.append(abs_td)
    log("Tool search paths: %s" % search_paths)

    # Load tools
    tool_specs = meta.get("tools", [])
    if isinstance(tool_specs, str):
        tool_specs = [t.strip() for t in tool_specs.split(",")]
    tools = {}
    if tool_specs:
        tools = load_tools(tool_specs, search_paths)
        log("Loaded %d tools: %s" % (len(tools), list(tools.keys())))

    if provider == "test":
        response = load_test_response(prompt_path)
        test_provider = response.get("_provider", "openai")
        result = extract_response(response, output_config, test_provider)
        print(result)
        return

    base_url = get_conf("base_url") or get_base_url()
    if base_url:
        url, api_key = get_provider_config(provider, base_url)
        effective_provider = "openai"
    else:
        url, api_key = get_provider_config(provider)
        effective_provider = provider

    # Check cache
    cached_response = None
    key = None
    if use_cache:
        key = cache_key(prompt, meta)
        log("Cache key: %s" % key)
        cached_response = cache_get(key)

    if cached_response:
        response = cached_response
        cached_provider = response.get("_provider", effective_provider)
        result = extract_response(response, output_config, cached_provider)
        print(result)
        return

    # Build initial messages
    messages = [{"role": "user", "content": prompt}]

    # Tool execution loop
    while True:
        response = make_request(url, api_key, model, messages, output_config,
                                effective_provider, tools if tools else None)

        # Print any text content immediately
        text_content = extract_text_content(response, effective_provider)
        if text_content:
            print(text_content)

        # Check for tool calls
        tool_calls = extract_tool_calls(response, effective_provider)

        # Filter out 'extract' tool calls - those are for structured output
        user_tool_calls = [tc for tc in tool_calls if tc["name"] != "extract"]

        if not user_tool_calls:
            # No more tool calls, we're done
            if use_cache and key:
                cache_set(key, response, effective_provider)
            if args.save_response:
                save_response(response, effective_provider, args.save_response)
            # If there was an extract tool call, output that
            for tc in tool_calls:
                if tc["name"] == "extract":
                    print(json.dumps(tc["arguments"], indent=2))
                    return
            # Otherwise we already printed text content above
            if not text_content:
                result = extract_response(response, output_config,
                                          effective_provider)
                if result:
                    print(result)
            return

        # Add assistant message to conversation
        messages.append(build_assistant_message(response, effective_provider))

        # Process each tool call
        for tc in user_tool_calls:
            tool_name = tc["name"]
            tool_args = tc["arguments"]

            if tool_name not in tools:
                error_msg = "Unknown tool: %s" % tool_name
                print("%s%s%s" % (RED, error_msg, RESET), file=sys.stderr)
                messages.append(build_tool_result_message(
                    tc, None, error_msg, effective_provider))
                continue

            tool_func = tools[tool_name]["func"]

            # Always print tool call summary
            print_tool_call(tool_name, tool_args)

            # Check if safe-yes is enabled and tool is safe
            if get_conf("safe_yes") and is_tool_safe(tool_func):
                log("Auto-approving safe tool: %s" % tool_name)
                approved = True
            else:
                # Prompt user for confirmation
                approved = prompt_user_for_tool(tool_name, tool_args)

            if not approved:
                error_msg = "Tool execution declined by user"
                messages.append(build_tool_result_message(
                    tc, None, error_msg, effective_provider))
                continue

            # Execute the tool
            result, error = execute_tool(tool_func, tool_args)

            if error:
                print("%s%s%s" % (RED, error, RESET), file=sys.stderr)

            messages.append(build_tool_result_message(
                tc, result, error, effective_provider))


HELP_EPILOG = """\
Input:
  Pipe JSON to set template variables: echo '{"name": "World"}' | runprompt hello.prompt
  Pipe text for {{STDIN}} variable:    echo "some text" | runprompt summarize.prompt
  Pass args for {{ARGS}} variable:     runprompt hello.prompt Some text here

Config files (lowest to highest priority):
  ~/.runprompt/config.yml
  $XDG_CONFIG_HOME/runprompt/config.yml (default: ~/.config/runprompt/config.yml)
  ./.runprompt/config.yml

Config file example:
  model: openai/gpt-4o
  tool_path:
    - ./tools
    - /shared/tools
  cache: true
  safe_yes: true
  openai_api_key: sk-...

Environment:
  ANTHROPIC_API_KEY       API key for Anthropic models
  OPENAI_API_KEY          API key for OpenAI models
  GOOGLE_API_KEY          API key for Google AI models
  OPENROUTER_API_KEY      API key for OpenRouter models
  OPENAI_BASE_URL         Custom OpenAI-compatible endpoint URL
  OPENAI_API_BASE         Custom endpoint URL (legacy OpenAI SDK v0.x style)
  BASE_URL                Custom endpoint URL (fallback)
  RUNPROMPT_<KEY>         Override config (e.g. RUNPROMPT_MODEL=openai/gpt-4o)

Config priority (highest wins): CLI flags > env vars > ./.runprompt > ~/.config > ~/.runprompt

Tools:
  Mark a function as safe by setting fn.safe = True after the definition:
  
    def my_safe_tool(x: str):
        \"\"\"A safe tool that only reads data.\"\"\"
        return "result"
    my_safe_tool.safe = True
  
  Safe tools are auto-approved when --safe-yes is passed.

Examples:
  runprompt hello.prompt
  runprompt hello.prompt Some text to process
  echo '{"name": "World"}' | runprompt hello.prompt
  runprompt --model openai/gpt-4o hello.prompt
  runprompt -v --save-response out.json hello.prompt
  runprompt --cache hello.prompt
  runprompt --safe-yes tool_prompt.prompt
  OPENAI_BASE_URL=http://localhost:11434/v1 runprompt hello.prompt

Overrides:
  --<key>=<value>         Override frontmatter value (e.g. --model=openai/gpt-4o)
  --<key> <value>         Override frontmatter value (e.g. --model openai/gpt-4o)
"""

def parse_args(args):
    parser = argparse.ArgumentParser(
        description="Run Dotprompt (.prompt) files from the command line.",
        add_help=True, formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=HELP_EPILOG)
    parser.add_argument("-v", "--verbose", action="store_true",
                        help="Show request/response details")
    parser.add_argument("-c", "--cache", action="store_true",
                        help="Enable response caching")
    parser.add_argument("--clear-cache", action="store_true",
                        help="Clear the response cache and exit")
    parser.add_argument("--safe-yes", action="store_true",
                        help="Auto-approve tool calls for safe functions")
    parser.add_argument("--save-response", metavar="FILE",
                        help="Save raw API response to file")
    parser.add_argument("--base-url", "--openai-base-url", metavar="URL",
                        help="Use custom OpenAI-compatible endpoint")
    parser.add_argument("--tool-path", action="append", default=[],
                        metavar="PATH", help="Add directory to tool import path")
    parsed, unknown = parser.parse_known_args(args)
    # Parse unknown args for --key=value overrides and extra positional args
    parsed.overrides = {}
    parsed.remaining = []
    i = 0
    while i < len(unknown):
        arg = unknown[i]
        if arg.startswith("--"):
            if "=" in arg:
                key, val = arg[2:].split("=", 1)
                parsed.overrides[normalize_key(key)] = parse_yaml_value(val)
            elif i + 1 < len(unknown) and not unknown[i + 1].startswith("-"):
                parsed.overrides[normalize_key(arg[2:])] = parse_yaml_value(
                    unknown[i + 1])
                i += 1
            else:
                parsed.overrides[normalize_key(arg[2:])] = True
        else:
            parsed.remaining.append(arg)
        i += 1
    return parsed


def read_stdin():
    if sys.stdin.isatty():
        return None
    content = sys.stdin.read()
    if not content:
        return None
    return content.strip() or None


# === PROMPT FILE HANDLING ===


def parse_prompt_file(path):
    with open(path, "r") as f:
        content = f.read()
    # Skip shebang line if present
    if content.startswith("#!"):
        content = content.split("\n", 1)[1] if "\n" in content else ""
    # Handle ---frontmatter---template format
    if content.startswith("---"):
        parts = content.split("---", 2)
        if len(parts) >= 3:
            meta_str = parts[1].strip()
            template = parts[2].strip()
            meta = parse_yaml(meta_str)
            return meta, template
        return {}, content.strip()
    # Handle frontmatter---template format (no opening ---)
    if "---" in content:
        parts = content.split("---", 1)
        meta_str = parts[0].strip()
        template = parts[1].strip()
        meta = parse_yaml(meta_str)
        return meta, template
    # No frontmatter delimiter found
    return {}, content.strip()


def parse_yaml(s):
    result = {}
    stack = [(result, -1)]
    current_list = None
    current_list_key = None
    current_list_indent = -1
    for line in s.split("\n"):
        if not line.strip() or line.strip().startswith("#"):
            continue
        indent = len(line) - len(line.lstrip())
        # Check if this is a list item
        list_match = re.match(r"^(\s*)-\s*(.*)", line)
        if list_match:
            item_value = list_match.group(2).strip()
            if current_list is not None and indent > current_list_indent:
                current_list.append(parse_yaml_value(item_value) if item_value else item_value)
                continue
        # Not a list item or different context - reset list tracking
        if current_list is not None and indent <= current_list_indent:
            current_list = None
            current_list_key = None
            current_list_indent = -1
        while stack and indent <= stack[-1][1]:
            stack.pop()
        if not stack:
            stack = [(result, -1)]
        match = re.match(r"^(\s*)([^:]+):\s*(.*)", line)
        if not match:
            continue
        key = match.group(2).strip()
        value = match.group(3).strip()
        parent = stack[-1][0]
        if value:
            parent[key] = parse_yaml_value(value)
        else:
            parent[key] = {}
            stack.append((parent[key], indent))
            # Set up for potential list children
            current_list_key = key
            current_list = []
            parent[key] = current_list
            current_list_indent = indent
    # Convert empty lists back to empty dicts
    def fix_empty(obj):
        if isinstance(obj, dict):
            for k, v in obj.items():
                if isinstance(v, list) and len(v) == 0:
                    obj[k] = {}
                else:
                    fix_empty(v)
    fix_empty(result)
    return result


def parse_yaml_value(s):
    s = s.strip()
    if not s:
        return None
    if s.lower() == "true":
        return True
    if s.lower() == "false":
        return False
    if re.match(r"^-?\d+$", s):
        return int(s)
    if re.match(r"^-?\d+\.\d+$", s):
        return float(s)
    if "\n" in s or s.startswith("{"):
        try:
            return json.loads(s)
        except ValueError:
            pass
        parsed = parse_yaml(s)
        if parsed:
            return parsed
    return s


def apply_overrides(meta):
    """Apply RUNPROMPT_* env vars to prompt metadata (for prompt-specific overrides)."""
    for key in CONFIG["env"]:
        # Skip config-level keys, only apply prompt-specific overrides
        if key in CONFIG_KEYS:
            continue
        value = CONFIG["env"][key]
        if value is not None:
            log("Override from env RUNPROMPT_%s: %s" % (key.upper(), value))
            meta[key] = value
    return meta


# === TEMPLATE RENDERING ===


def render_template(template, variables):
    def lookup(name, ctx):
        name = name.strip()
        if name == ".":
            return ctx
        # Handle @index, @first, @last, @key
        if name.startswith("@"):
            return ctx.get(name, "")
        for part in name.split("."):
            if isinstance(ctx, dict):
                ctx = ctx.get(part, "")
            else:
                return ""
        return ctx

    def render(tmpl, ctx):
        # Remove comments: {{! ... }}
        tmpl = re.sub(r"\{\{!.*?\}\}", "", tmpl, flags=re.DOTALL)

        # Process {{#each key}}...{{/each}}
        def each_replace(match):
            key = match.group(1)
            inner = match.group(2)
            val = lookup(key, ctx)
            result = []
            if isinstance(val, list):
                for i, item in enumerate(val):
                    if isinstance(item, dict):
                        item_ctx = dict(item)
                    else:
                        item_ctx = {}
                    item_ctx["@index"] = i
                    item_ctx["@first"] = (i == 0)
                    item_ctx["@last"] = (i == len(val) - 1)
                    item_ctx["."] = item
                    result.append(render(inner, item_ctx))
            elif isinstance(val, dict):
                keys = list(val.keys())
                for i, k in enumerate(keys):
                    item = val[k]
                    if isinstance(item, dict):
                        item_ctx = dict(item)
                    else:
                        item_ctx = {}
                    item_ctx["@key"] = k
                    item_ctx["@index"] = i
                    item_ctx["@first"] = (i == 0)
                    item_ctx["@last"] = (i == len(keys) - 1)
                    item_ctx["."] = item
                    result.append(render(inner, item_ctx))
            return "".join(result)

        tmpl = re.sub(
            r"\{\{#each\s+(\w+)\}\}(.*?)\{\{/each\}\}",
            each_replace,
            tmpl,
            flags=re.DOTALL
        )

        # Process sections: {{#key}}...{{/key}}
        def section_replace(match):
            key = match.group(1)
            inner = match.group(2)
            val = lookup(key, ctx)
            if isinstance(val, list):
                result = []
                for i, item in enumerate(val):
                    if isinstance(item, dict):
                        item_ctx = dict(item)
                    else:
                        item_ctx = {"_value": item}
                    item_ctx["@index"] = i
                    item_ctx["@first"] = (i == 0)
                    item_ctx["@last"] = (i == len(val) - 1)
                    item_ctx["."] = item
                    result.append(render(inner, item_ctx))
                return "".join(result)
            if val:
                new_ctx = val if isinstance(val, dict) else ctx
                return render(inner, new_ctx)
            return ""

        # Process inverted sections: {{^key}}...{{/key}}
        def inverted_replace(match):
            key = match.group(1)
            inner = match.group(2)
            val = lookup(key, ctx)
            if not val or (isinstance(val, list) and len(val) == 0):
                return render(inner, ctx)
            return ""

        # Process {{#if}} and {{#unless}} with shared logic
        def conditional_replace(match, invert=False):
            key = match.group(1)
            inner = match.group(2)
            val = lookup(key, ctx)
            is_truthy = bool(val) and val != "" and \
                not (isinstance(val, list) and len(val) == 0)
            if invert:
                is_truthy = not is_truthy
            # Find {{else}} not inside nested conditionals
            depth = 0
            else_pos = None
            i = 0
            tag = "{{#unless" if invert else "{{#if"
            end_tag = "{{/unless}}" if invert else "{{/if}}"
            while i < len(inner):
                if inner[i:].startswith(tag):
                    depth += 1
                elif inner[i:].startswith(end_tag):
                    depth -= 1
                elif inner[i:].startswith("{{else}}") and depth == 0:
                    else_pos = i
                    break
                i += 1
            if else_pos is not None:
                return inner[:else_pos] if is_truthy else inner[else_pos + 8:]
            return inner if is_truthy else ""

        # Process if/unless in a single loop to handle mixed nesting
        if_pattern = re.compile(
            r"\{\{#if\s+([\w.]+)\}\}((?:(?!\{\{#if)(?!\{\{/if\}\})(?!\{\{#unless)(?!\{\{/unless\}\}).)*?)\{\{/if\}\}",
            re.DOTALL
        )
        unless_pattern = re.compile(
            r"\{\{#unless\s+([\w.]+)\}\}((?:(?!\{\{#if)(?!\{\{/if\}\})(?!\{\{#unless)(?!\{\{/unless\}\}).)*?)\{\{/unless\}\}",
            re.DOTALL
        )
        while True:
            if_match = if_pattern.search(tmpl)
            unless_match = unless_pattern.search(tmpl)
            if not if_match and not unless_match:
                break
            if if_match and (not unless_match or if_match.start() < unless_match.start()):
                tmpl = if_pattern.sub(lambda m: conditional_replace(m, False), tmpl, count=1)
            else:
                tmpl = unless_pattern.sub(lambda m: conditional_replace(m, True), tmpl, count=1)

        # Process sections first (innermost first via non-greedy)
        tmpl = re.sub(
            r"\{\{#(@?\w+)\}\}(.*?)\{\{/\1\}\}",
            section_replace,
            tmpl,
            flags=re.DOTALL
        )
        tmpl = re.sub(
            r"\{\{\^(@?\w+)\}\}(.*?)\{\{/\1\}\}",
            inverted_replace,
            tmpl,
            flags=re.DOTALL
        )

        # Process variables
        def var_replace(match):
            key = match.group(1).strip()
            val = lookup(key, ctx)
            # Handle special "." lookup for non-dict items in lists
            if key == "." and "." in ctx:
                return str(ctx["."])
            return str(val)
        tmpl = re.sub(r"\{\{([^#^/}]+)\}\}", var_replace, tmpl)

        return tmpl

    return render(template, variables)


# === MODEL/PROVIDER CONFIGURATION ===


def parse_model_string(model_str):
    if model_str == "test":
        return "test", None
    parts = model_str.split("/", 1)
    if len(parts) == 1:
        return None, parts[0]
    return parts[0], parts[1]


def get_base_url():
    """Get base URL from legacy env vars (fallback after config cascade)."""
    return (os.environ.get("OPENAI_BASE_URL") or
            os.environ.get("OPENAI_API_BASE") or
            os.environ.get("BASE_URL"))


def get_provider_config(provider, base_url=None):
    if base_url:
        url = base_url.rstrip("/") + "/chat/completions"
        api_key = get_api_key("openai") or ""
        log("Using custom base URL: %s" % url)
        return url, api_key
    if provider not in PROVIDERS:
        print("Unknown provider: %s" % provider, file=sys.stderr)
        sys.exit(1)
    config = PROVIDERS[provider]
    api_key = get_api_key(provider)
    if not api_key:
        print("Missing API key: %s" % config["env"], file=sys.stderr)
        sys.exit(1)
    return config["url"], api_key


# === API REQUEST/RESPONSE ===


def make_request(url, api_key, model, messages, output_config, provider, tools=None):
    headers = {
        "Content-Type": "application/json",
    }
    if provider == "anthropic":
        headers["x-api-key"] = api_key
        headers["anthropic-version"] = "2023-06-01"
    else:
        headers["Authorization"] = "Bearer %s" % api_key
    if provider == "anthropic":
        # Convert messages to Anthropic format
        system_content = None
        anthropic_messages = []
        for msg in messages:
            if msg["role"] == "system":
                system_content = msg["content"]
            else:
                anthropic_messages.append(msg)
        body = {
            "model": model,
            "max_tokens": 4096,
            "messages": anthropic_messages,
        }
        if system_content:
            body["system"] = system_content
        all_tools = []
        if output_config and output_config.get("schema"):
            all_tools.append(to_anthropic_tool(build_schema_tool(
                output_config["schema"])))
        if tools:
            for tool_info in tools.values():
                all_tools.append(to_anthropic_tool(tool_info["schema"]))
        if all_tools:
            body["tools"] = all_tools
            if output_config and output_config.get("schema") and not tools:
                body["tool_choice"] = {"type": "tool", "name": "extract"}
    else:
        body = {
            "model": model,
            "messages": messages,
        }
        all_tools = []
        if output_config and output_config.get("schema"):
            all_tools.append(build_schema_tool(output_config["schema"]))
        if tools:
            for tool_info in tools.values():
                all_tools.append(tool_info["schema"])
        if all_tools:
            body["tools"] = all_tools
            if output_config and output_config.get("schema") and not tools:
                body["tool_choice"] = {
                    "type": "function",
                    "function": {"name": "extract"}
                }
    data = json.dumps(body).encode("utf-8")
    log("Request URL: %s" % url)
    log("Request body: %s" % json.dumps(body, indent=2))
    req = urllib.request.Request(url, data=data, headers=headers, method="POST")
    try:
        with urllib.request.urlopen(req, timeout=TIMEOUT) as resp:
            response_body = resp.read().decode("utf-8")
            log("Response: %s" % response_body)
            return json.loads(response_body)
    except urllib.error.HTTPError as e:
        error_body = e.read().decode("utf-8")
        log("Error response: %s" % error_body)
        message = extract_error_message(error_body)
        print("%s%s%s" % (RED, message, RESET), file=sys.stderr)
        sys.exit(1)


def extract_response(response, output_config, provider):
    if provider == "anthropic":
        content = response.get("content", [])
        for block in content:
            if block.get("type") == "tool_use" and block.get("name") == "extract":
                return json.dumps(block.get("input", {}), indent=2)
    else:
        choices = response.get("choices", [])
        if choices:
            message = choices[0].get("message", {})
            tool_calls = message.get("tool_calls", [])
            for tc in tool_calls:
                if tc.get("function", {}).get("name") == "extract":
                    return tc.get("function", {}).get("arguments", "{}")
    return extract_text_content(response, provider)


def extract_text_content(response, provider):
    if provider == "anthropic":
        content = response.get("content", [])
        texts = []
        for block in content:
            if block.get("type") == "text":
                texts.append(block.get("text", ""))
        return "".join(texts)
    else:
        choices = response.get("choices", [])
        if choices:
            message = choices[0].get("message", {})
            return message.get("content", "") or ""
        return ""


def extract_tool_calls(response, provider):
    tool_calls = []
    if provider == "anthropic":
        content = response.get("content", [])
        for block in content:
            if block.get("type") == "tool_use":
                tool_calls.append({
                    "id": block.get("id", ""),
                    "name": block.get("name", ""),
                    "arguments": block.get("input", {}),
                })
    else:
        choices = response.get("choices", [])
        if choices:
            message = choices[0].get("message", {})
            for tc in message.get("tool_calls", []):
                args_str = tc.get("function", {}).get("arguments", "{}")
                try:
                    args = json.loads(args_str)
                except ValueError:
                    args = {}
                tool_calls.append({
                    "id": tc.get("id", ""),
                    "name": tc.get("function", {}).get("name", ""),
                    "arguments": args,
                })
    return tool_calls


def extract_error_message(error_body):
    try:
        data = json.loads(error_body)
        if "error" in data:
            err = data["error"]
            if isinstance(err, dict):
                err_type = err.get("type", "")
                message = err.get("message", "")
                if err_type and message:
                    return "%s: %s" % (err_type, message)
                if message:
                    return message
                if err_type:
                    return err_type
            if isinstance(err, str):
                return err
        if "message" in data:
            return data["message"]
    except ValueError:
        pass
    return error_body


def to_anthropic_tool(tool_schema):
    func = tool_schema["function"]
    return {
        "name": func["name"],
        "description": func["description"],
        "input_schema": func["parameters"],
    }


def build_assistant_message(response, provider):
    if provider == "anthropic":
        return {
            "role": "assistant",
            "content": response.get("content", []),
        }
    else:
        choices = response.get("choices", [])
        if choices:
            return choices[0].get("message", {"role": "assistant", "content": ""})
        return {"role": "assistant", "content": ""}


def build_tool_result_message(tool_call, result, error, provider):
    if error:
        content = json.dumps({"error": error})
    else:
        content = json.dumps(result) if not isinstance(result, str) else result
    if provider == "anthropic":
        return {
            "role": "user",
            "content": [{
                "type": "tool_result",
                "tool_use_id": tool_call["id"],
                "content": content,
            }]
        }
    return {
        "role": "tool",
        "tool_call_id": tool_call["id"],
        "content": content,
    }


# === TOOL LOADING & SCHEMA ===


def load_tools(tool_specs, search_paths):
    tools = {}  # name -> {"schema": ..., "func": ...}
    for spec in tool_specs:
        # Handle builtin tools
        if spec.startswith("builtin."):
            builtin_spec = spec[8:]  # Remove "builtin." prefix
            if builtin_spec == "*":
                # Import all builtin tools
                for name, func in BUILTIN_TOOLS.items():
                    schema = function_to_tool_schema(func)
                    if schema:
                        tools[name] = {"schema": schema, "func": func}
                        log("Loaded builtin tool: %s" % name)
            else:
                # Import specific builtin tool
                if builtin_spec in BUILTIN_TOOLS:
                    func = BUILTIN_TOOLS[builtin_spec]
                    schema = function_to_tool_schema(func)
                    if schema:
                        tools[builtin_spec] = {"schema": schema, "func": func}
                        log("Loaded builtin tool: %s" % builtin_spec)
                else:
                    print("%sWarning: Unknown builtin tool '%s'%s" %
                          (YELLOW, builtin_spec, RESET), file=sys.stderr)
            continue
        if spec.endswith(".*"):
            # Import all functions from module
            module_name = spec[:-2]
            try:
                module = load_module_from_path(module_name, search_paths)
                if module is None:
                    raise ImportError("No module named '%s'" % module_name)
                for name in dir(module):
                    if name.startswith("_"):
                        continue
                    obj = getattr(module, name)
                    if callable(obj) and inspect.getdoc(obj):
                        schema = function_to_tool_schema(obj)
                        if schema:
                            tools[name] = {"schema": schema, "func": obj}
                            log("Loaded tool: %s from %s" % (name, module_name))
            except Exception as e:
                print("%sWarning: Could not import tool '%s': %s%s" %
                      (YELLOW, spec, e, RESET), file=sys.stderr)
        else:
            # Import specific function
            parts = spec.rsplit(".", 1)
            if len(parts) != 2:
                print("%sWarning: Invalid tool spec '%s'%s" %
                      (YELLOW, spec, RESET), file=sys.stderr)
                continue
            module_name, func_name = parts
            try:
                module = load_module_from_path(module_name, search_paths)
                if module is None:
                    raise ImportError("No module named '%s'" % module_name)
                if not hasattr(module, func_name):
                    raise AttributeError("Module '%s' has no function '%s'" %
                                         (module_name, func_name))
                func = getattr(module, func_name)
                if not callable(func):
                    raise TypeError("'%s' is not callable" % func_name)
                schema = function_to_tool_schema(func)
                if schema:
                    tools[func_name] = {"schema": schema, "func": func}
                    log("Loaded tool: %s from %s" % (func_name, module_name))
                else:
                    print("%sWarning: Function '%s' has no docstring%s" %
                          (YELLOW, func_name, RESET), file=sys.stderr)
            except Exception as e:
                print("%sWarning: Could not import tool '%s': %s%s" %
                      (YELLOW, spec, e, RESET), file=sys.stderr)
    return tools


def load_module_from_path(module_name, search_paths):
    parts = module_name.split(".")
    for base_path in search_paths:
        # Build list of candidate paths to try
        candidates = [os.path.join(base_path, module_name + ".py")]
        if len(parts) > 1:
            candidates.append(os.path.join(base_path, *parts[:-1], parts[-1] + ".py"))
            candidates.append(os.path.join(base_path, *parts, "__init__.py"))
        for file_path in candidates:
            if os.path.exists(file_path):
                spec = importlib.util.spec_from_file_location(module_name, file_path)
                module = importlib.util.module_from_spec(spec)
                sys.modules[module_name] = module
                spec.loader.exec_module(module)
                return module
    return None


def function_to_tool_schema(func):
    doc = inspect.getdoc(func)
    if not doc:
        return None
    sig = inspect.signature(func)
    properties = {}
    required = []
    for param_name, param in sig.parameters.items():
        if param_name in ("self", "cls"):
            continue
        param_type = param.annotation
        if param_type is inspect.Parameter.empty:
            param_type = None
        json_type = python_type_to_json_type(param_type)
        properties[param_name] = {"type": json_type}
        if param.default is inspect.Parameter.empty:
            required.append(param_name)
    return build_tool_schema(func.__name__, doc, properties, required)


def python_type_to_json_type(py_type):
    if py_type is None:
        return "string"
    type_name = getattr(py_type, "__name__", str(py_type))
    mapping = {
        "str": "string",
        "int": "integer",
        "float": "number",
        "bool": "boolean",
        "list": "array",
        "dict": "object",
    }
    return mapping.get(type_name, "string")


def build_tool_schema(name, description, properties, required):
    return {
        "type": "function",
        "function": {
            "name": name,
            "description": description,
            "parameters": {
                "type": "object",
                "properties": properties,
                "required": required,
            },
        },
    }


def build_schema_tool(schema):
    properties = {}
    required = []
    for key, value in schema.items():
        clean_key = key.rstrip("?")
        is_optional = key.endswith("?")
        parts = value.split(",", 1) if isinstance(value, str) else [value]
        type_str = parts[0].strip() if parts else "string"
        description = parts[1].strip() if len(parts) > 1 else ""
        json_type = "string"
        if type_str == "number":
            json_type = "number"
        elif type_str == "boolean":
            json_type = "boolean"
        prop = {"type": json_type}
        if description:
            prop["description"] = description
        properties[clean_key] = prop
        if not is_optional:
            required.append(clean_key)
    return build_tool_schema("extract", "Extract structured data", properties,
                             required)


# === TOOL EXECUTION & USER INTERACTION ===


def execute_tool(tool_func, args):
    try:
        result = tool_func(**args)
        return result, None
    except Exception as e:
        error_msg = "%s: %s" % (type(e).__name__, str(e))
        return None, error_msg


def prompt_user_for_tool(tool_name, args):
    while True:
        response = read_tty_line("Run this tool? [Y/n]: ")
        if response is None:
            return True
        if response == "" or response.lower() in ("y", "yes"):
            return True
        if response.lower() in ("n", "no"):
            return False
        print("Please enter 'y' or 'n'", file=sys.stderr)


def is_tool_safe(tool_func):
    return getattr(tool_func, 'safe', False)


def print_tool_call(tool_name, args):
    summary = format_tool_call_summary(tool_name, args)
    print("%s%s%s" % (YELLOW, summary, RESET), file=sys.stderr)


def format_tool_call_summary(tool_name, args):
    if not args:
        return "Tool: %s()" % tool_name
    arg_parts = []
    for k, v in args.items():
        q = '"' if isinstance(v, str) else ''
        arg_parts.append('%s=%s%s%s' % (k, q, truncate_value(v, 30), q))
    args_str = ", ".join(arg_parts)
    if len(args_str) > 60:
        args_str = args_str[:57] + "..."
    return "Tool: %s(%s)" % (tool_name, args_str)


def truncate_value(value, max_len=50):
    s = str(value)
    return s if len(s) <= max_len else s[:max_len - 3] + "..."


def read_tty_line(prompt_text):
    # If stdin is a tty (e.g. running in a pty for testing), read from it directly
    if sys.stdin.isatty():
        sys.stderr.write(prompt_text)
        sys.stderr.flush()
        return sys.stdin.readline().strip()
    # Try /dev/tty for interactive input when stdin is a pipe
    try:
        tty = open("/dev/tty", "r")
        sys.stderr.write(prompt_text)
        sys.stderr.flush()
        response = tty.readline().strip()
        tty.close()
        return response
    except (IOError, OSError):
        pass
    # No input available
    return None


# === CACHING ===


def cache_key(rendered_prompt, effective_meta):
    data = json.dumps({
        "prompt": rendered_prompt,
        "meta": effective_meta,
    }, sort_keys=True)
    return hashlib.sha256(data.encode()).hexdigest()


def cache_get(key):
    cache_dir = get_cache_dir()
    cache_file = os.path.join(cache_dir, "%s.json" % key)
    if os.path.exists(cache_file):
        log("Cache hit: %s" % cache_file)
        with open(cache_file, "r") as f:
            return json.load(f)
    log("Cache miss")
    return None


def cache_set(key, response, provider):
    cache_dir = get_cache_dir()
    if not os.path.exists(cache_dir):
        os.makedirs(cache_dir)
    cache_file = os.path.join(cache_dir, "%s.json" % key)
    response_with_provider = {"_provider": provider}
    response_with_provider.update(response)
    with open(cache_file, "w") as f:
        json.dump(response_with_provider, f, indent=2)
    log("Cached response: %s" % cache_file)


def clear_cache():
    cache_dir = get_cache_dir()
    if not os.path.exists(cache_dir):
        print("Cache directory does not exist: %s" % cache_dir)
        return
    count = 0
    for filename in os.listdir(cache_dir):
        if filename.endswith(".json"):
            os.remove(os.path.join(cache_dir, filename))
            count += 1
    print("Cleared %d cached response(s) from %s" % (count, cache_dir))


def get_cache_dir():
    from_conf = get_conf("cache_dir")
    if from_conf:
        return from_conf
    xdg_cache = os.environ.get("XDG_CACHE_HOME", os.path.expanduser("~/.cache"))
    return os.path.join(xdg_cache, "runprompt")


# === TEST/DEBUG UTILITIES ===


def load_test_response(prompt_path):
    test_file = prompt_path + ".test-response"
    if not os.path.exists(test_file):
        print("Test response file not found: %s" % test_file, file=sys.stderr)
        sys.exit(1)
    with open(test_file, "r") as f:
        content = f.read()
    log("Loaded test response from: %s" % test_file)
    return json.loads(content)


def save_response(response, provider, save_path):
    response_with_provider = {"_provider": provider}
    response_with_provider.update(response)
    with open(save_path, "w") as f:
        json.dump(response_with_provider, f, indent=2)
    log("Saved response to: %s" % save_path)


def log(msg):
    if get_conf("verbose", False):
        print(msg, file=sys.stderr)


# === BUILTIN TOOLS ===


def _fetch_clean_simple(url: str):
    """Simple HTML fetcher that extracts visible text (fallback)."""
    from html.parser import HTMLParser

    class TextExtractor(HTMLParser):
        SKIP_TAGS = {'script', 'style', 'head', 'meta', 'link', 'noscript', 'svg'}

        def __init__(self):
            super().__init__()
            self.text = []
            self.skip_depth = 0

        def handle_starttag(self, tag, attrs):
            if tag == 'body':
                self.skip_depth = 0
            elif tag in self.SKIP_TAGS:
                self.skip_depth += 1
            elif tag in ('p', 'br', 'div', 'li', 'tr', 'h1', 'h2', 'h3', 'h4',
                         'h5', 'h6'):
                self.text.append('\n')

        def handle_endtag(self, tag):
            if tag in self.SKIP_TAGS and self.skip_depth > 0:
                self.skip_depth -= 1
            elif tag in ('p', 'div', 'li', 'tr', 'h1', 'h2', 'h3', 'h4', 'h5',
                         'h6'):
                self.text.append('\n')

        def handle_data(self, data):
            if self.skip_depth == 0:
                self.text.append(data)

        def get_text(self):
            import html
            text = ''.join(self.text)
            lines = [' '.join(line.split()) for line in text.split('\n')]
            text = '\n'.join(lines)
            while '\n\n\n' in text:
                text = text.replace('\n\n\n', '\n\n')
            return html.unescape(text.strip())

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                      'AppleWebKit/537.36 (KHTML, like Gecko) '
                      'Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
    }
    req = urllib.request.Request(url, headers=headers)
    with urllib.request.urlopen(req, timeout=30) as resp:
        html_content = resp.read().decode('utf-8', errors='replace')
    extractor = TextExtractor()
    extractor.feed(html_content)
    return extractor.get_text()


def calculator(expression: str):
    """Evaluate a mathematical expression safely.

    Supports arithmetic (+, -, *, /, //, %, **), scientific functions
    (sin, cos, tan, log, sqrt, exp, etc.), and constants (pi, e, tau).
    """
    import ast
    import operator
    import math

    allowed_ops = {
        ast.Add: operator.add,
        ast.Sub: operator.sub,
        ast.Mult: operator.mul,
        ast.Div: operator.truediv,
        ast.FloorDiv: operator.floordiv,
        ast.Mod: operator.mod,
        ast.Pow: operator.pow,
        ast.USub: operator.neg,
        ast.UAdd: operator.pos,
    }

    allowed_functions = {
        'sin': math.sin, 'cos': math.cos, 'tan': math.tan,
        'asin': math.asin, 'acos': math.acos, 'atan': math.atan,
        'atan2': math.atan2,
        'sinh': math.sinh, 'cosh': math.cosh, 'tanh': math.tanh,
        'asinh': math.asinh, 'acosh': math.acosh, 'atanh': math.atanh,
        'exp': math.exp, 'log': math.log, 'log10': math.log10,
        'log2': math.log2, 'sqrt': math.sqrt, 'pow': pow,
        'abs': abs, 'ceil': math.ceil, 'floor': math.floor,
        'trunc': math.trunc, 'round': round,
        'degrees': math.degrees, 'radians': math.radians,
        'factorial': math.factorial, 'gcd': math.gcd,
        'max': max, 'min': min, 'sum': sum,
    }
    if hasattr(math, 'lcm'):
        allowed_functions['lcm'] = math.lcm

    allowed_constants = {
        'pi': math.pi, 'e': math.e, 'tau': math.tau,
        'inf': math.inf, 'nan': math.nan,
    }

    def _eval(node):
        if isinstance(node, ast.Expression):
            return _eval(node.body)
        elif isinstance(node, ast.Constant):
            if isinstance(node.value, (int, float, complex)):
                return node.value
            raise ValueError("Only numbers allowed, not %s" %
                             type(node.value).__name__)
        elif isinstance(node, ast.Num):
            return node.n
        elif isinstance(node, ast.Str):
            raise ValueError("Only numbers allowed, not str")
        elif isinstance(node, ast.BinOp):
            if type(node.op) not in allowed_ops:
                raise ValueError("Operation not allowed: %s" %
                                 type(node.op).__name__)
            return allowed_ops[type(node.op)](_eval(node.left),
                                              _eval(node.right))
        elif isinstance(node, ast.UnaryOp):
            if type(node.op) not in allowed_ops:
                raise ValueError("Operation not allowed: %s" %
                                 type(node.op).__name__)
            return allowed_ops[type(node.op)](_eval(node.operand))
        elif isinstance(node, ast.Call):
            if not isinstance(node.func, ast.Name):
                raise ValueError("Only simple function calls allowed")
            func_name = node.func.id
            if func_name not in allowed_functions:
                raise ValueError("Function not allowed: %s" % func_name)
            args = [_eval(arg) for arg in node.args]
            return allowed_functions[func_name](*args)
        elif isinstance(node, ast.Name):
            if node.id in allowed_constants:
                return allowed_constants[node.id]
            raise ValueError("Name not allowed: %s" % node.id)
        elif isinstance(node, ast.List):
            return [_eval(item) for item in node.elts]
        elif isinstance(node, ast.Tuple):
            return tuple(_eval(item) for item in node.elts)
        else:
            raise ValueError("Node type not allowed: %s" % type(node).__name__)

    tree = ast.parse(expression, mode='eval')
    return _eval(tree)


calculator.safe = True


def fetch_clean(url: str):
    """Fetch a web page and extract its main content as HTML.

    Uses Firefox Reader View via Playwright for best results. Falls back to
    simple text extraction if Playwright is not installed.
    """
    try:
        from playwright.sync_api import sync_playwright
    except ImportError:
        print("%sWarning: playwright not installed. Using simple scraper. "
              "For better results install with:\n"
              "  pip install playwright && playwright install firefox%s" %
              (YELLOW, RESET), file=sys.stderr)
        return _fetch_clean_simple(url)
    with sync_playwright() as p:
        browser = p.firefox.launch(headless=True)
        context = browser.new_context()
        page = context.new_page()
        reader_url = "about:reader?url=%s" % url
        page.goto(reader_url)
        page.wait_for_timeout(1000)
        page.wait_for_selector(
            '[data-l10n-id="about-reader-loading"]',
            state='hidden',
            timeout=20000
        )
        html_content = page.evaluate("""() => {
            const header = document.querySelector('div.header');
            const content = document.querySelector('div.content');
            let result = '';
            if (header) result += header.innerHTML;
            if (content) result += content.innerHTML;
            return result || document.body.innerHTML;
        }""")
        browser.close()
        return html_content


fetch_clean.safe = True


BUILTIN_TOOLS = {
    "calculator": calculator,
    "fetch_clean": fetch_clean,
}


if __name__ == "__main__":
    main()
